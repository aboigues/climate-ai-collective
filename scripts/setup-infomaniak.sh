#!/bin/bash
#
# Script de setup pour dÃ©ployer Climate AI Collective sur Infomaniak Public Cloud
#

set -e

echo "ğŸŒ Climate AI Collective - Setup sur Infomaniak"
echo "================================================"
echo ""

# VÃ©rifications prÃ©alables
echo "ğŸ“‹ VÃ©rification des prÃ©requis..."

if ! command -v kubectl &> /dev/null; then
    echo "âŒ kubectl n'est pas installÃ©"
    echo "Installation: https://kubernetes.io/docs/tasks/tools/"
    exit 1
fi

if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 n'est pas installÃ©"
    exit 1
fi

echo "âœ… PrÃ©requis OK"
echo ""

# Configuration
echo "âš™ï¸  Configuration..."
read -p "Voulez-vous utiliser un fichier de configuration existant? (y/n): " use_config

if [ "$use_config" = "y" ]; then
    read -p "Chemin du fichier config.yaml: " config_path
    cp "$config_path" config.yaml
else
    echo "CrÃ©ation d'une nouvelle configuration..."
    cat > config.yaml <<EOF
# Climate AI Collective - Configuration

# Infomaniak
infomaniak:
  project_id: "your-project-id"
  region: "ch-dc1"  # Geneva datacenter
  s3_endpoint: "https://s3.infomaniak.com"
  s3_bucket: "climate-ai-data"

# Kubernetes
kubernetes:
  namespace: "climate-ai"
  gpu_node_pool: "gpu-l4-pool"

# LLM Endpoints
llm:
  orchestrator:
    replicas: 1
    gpu_count: 1
  mistral_large:
    replicas: 1
    gpu_count: 2
  deepseek:
    replicas: 1
    gpu_count: 1
  llama:
    replicas: 0  # Scale to zero
    gpu_count: 1

# GitHub
github:
  repo: "votre-org/climate-ai-collective"
  
# Monitoring
monitoring:
  enabled: true
  prometheus: true
  grafana: true
EOF
    
    echo "âš ï¸  Veuillez Ã©diter config.yaml avec vos valeurs"
    echo "Puis relancez ce script"
    exit 0
fi

echo ""
echo "ğŸ” Configuration des secrets..."

# VÃ©rifier si les secrets existent
if [ ! -f "kubernetes/base/storage/secrets.yaml" ]; then
    echo "CrÃ©ation du fichier secrets..."
    
    read -p "Hugging Face Token (pour tÃ©lÃ©charger les modÃ¨les): " hf_token
    read -p "GitHub Token (pour l'intÃ©gration): " gh_token
    read -p "S3 Access Key (Infomaniak): " s3_key
    read -sp "S3 Secret Key (Infomaniak): " s3_secret
    echo ""
    read -sp "PostgreSQL Password: " pg_password
    echo ""
    
    cat > kubernetes/base/storage/secrets.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: huggingface-secret
  namespace: climate-ai
type: Opaque
stringData:
  token: "${hf_token}"
---
apiVersion: v1
kind: Secret
metadata:
  name: github-secret
  namespace: climate-ai
type: Opaque
stringData:
  token: "${gh_token}"
---
apiVersion: v1
kind: Secret
metadata:
  name: s3-secret
  namespace: climate-ai
type: Opaque
stringData:
  access_key: "${s3_key}"
  secret_key: "${s3_secret}"
  endpoint: "https://s3.infomaniak.com"
---
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: climate-ai
type: Opaque
stringData:
  username: "climate_ai"
  password: "${pg_password}"
  database: "climate_ai_db"
EOF
    
    echo "âœ… Secrets crÃ©Ã©s"
else
    echo "âœ… Fichier secrets.yaml existe dÃ©jÃ "
fi

echo ""
echo "ğŸš€ DÃ©ploiement sur Kubernetes..."

# Connexion au cluster
echo "Configuration du contexte Kubernetes..."
read -p "Nom du cluster Kubernetes: " cluster_name

kubectl config use-context "$cluster_name" || {
    echo "âŒ Impossible de se connecter au cluster"
    echo "Configurez d'abord kubectl pour accÃ©der Ã  votre cluster Infomaniak"
    exit 1
}

# CrÃ©ation du namespace
echo "CrÃ©ation du namespace..."
kubectl apply -f kubernetes/base/namespace.yaml

# Application des secrets
echo "Application des secrets..."
kubectl apply -f kubernetes/base/storage/secrets.yaml

# CrÃ©ation des PVC
echo "CrÃ©ation des volumes de stockage..."
kubectl apply -f kubernetes/base/storage/pvc.yaml

# Attendre que les PVC soient bound
echo "Attente de la prÃ©paration des volumes..."
kubectl wait --for=jsonpath='{.status.phase}'=Bound \
    pvc/vllm-model-cache -n climate-ai --timeout=120s || {
    echo "âš ï¸  Timeout en attendant les PVC"
    echo "Les PVC sont peut-Ãªtre encore en cours de provisioning"
}

# DÃ©ploiement de l'orchestrateur
echo "DÃ©ploiement de l'orchestrateur..."
kubectl apply -f kubernetes/base/orchestrator/deployment.yaml

# DÃ©ploiement des LLM workers
echo "DÃ©ploiement des LLM workers..."
kubectl apply -f kubernetes/base/llm-workers/

echo ""
echo "â³ Attente du dÃ©marrage des pods..."
echo "Cela peut prendre 10-15 minutes (tÃ©lÃ©chargement des modÃ¨les)"
echo ""

# Surveiller les pods
kubectl get pods -n climate-ai -w &
WATCH_PID=$!

# Attendre que les pods soient prÃªts (timeout 20 minutes)
kubectl wait --for=condition=ready pod \
    -l component=llm \
    -n climate-ai \
    --timeout=1200s || {
    echo "âš ï¸  Certains pods ne sont pas prÃªts aprÃ¨s 20 minutes"
    echo "VÃ©rifiez les logs avec: kubectl logs -n climate-ai <pod-name>"
}

kill $WATCH_PID 2>/dev/null || true

echo ""
echo "âœ… DÃ©ploiement terminÃ©!"
echo ""
echo "ğŸ“Š Ã‰tat du cluster:"
kubectl get pods -n climate-ai
echo ""
kubectl get svc -n climate-ai
echo ""

echo "ğŸ‰ Climate AI Collective est dÃ©ployÃ©!"
echo ""
echo "ğŸ” Commandes utiles:"
echo "  - Voir les logs de l'orchestrateur:"
echo "    kubectl logs -f -n climate-ai -l app=orchestrator"
echo ""
echo "  - Voir l'Ã©tat des LLM:"
echo "    kubectl get pods -n climate-ai -l component=llm-worker"
echo ""
echo "  - AccÃ©der Ã  l'API de l'orchestrateur (port-forward):"
echo "    kubectl port-forward -n climate-ai svc/orchestrator-service 8000:8000"
echo ""
echo "  - Surveiller les ressources GPU:"
echo "    kubectl top pods -n climate-ai"
echo ""
echo "ğŸ“– Documentation: https://github.com/votre-org/climate-ai-collective"
echo ""
